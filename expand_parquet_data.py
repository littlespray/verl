#!/usr/bin/env python3
"""
æ‰©å±•parquetæ–‡ä»¶æ•°æ®çš„è„šæœ¬
ç”¨æ³•: python expand_parquet_data.py --directory /path/to/data --factor 3
"""

import argparse
import os
import shutil
import sys
from pathlib import Path

import pandas as pd


def expand_parquet_data(directory: str, factor: int, backup: bool = True):
    """
    æ‰©å±•æŒ‡å®šç›®å½•ä¸‹train.parquetæ–‡ä»¶çš„æ•°æ®
    
    Args:
        directory: åŒ…å«train.parquetæ–‡ä»¶çš„ç›®å½•è·¯å¾„
        factor: æ‰©å±•å€æ•°ï¼ˆå¿…é¡»å¤§äº0ï¼‰
        backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½æ–‡ä»¶
    """
    if factor <= 0:
        raise ValueError("æ‰©å±•å€æ•°å¿…é¡»å¤§äº0")
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    directory_path = Path(directory)
    parquet_file = directory_path / "train.parquet"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not parquet_file.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {parquet_file}")
    
    print(f"æ­£åœ¨è¯»å–æ–‡ä»¶: {parquet_file}")
    
    try:
        # è¯»å–åŸå§‹parquetæ–‡ä»¶
        df = pd.read_parquet(parquet_file)
        original_size = len(df)
        print(f"åŸå§‹æ•°æ®è¡Œæ•°: {original_size}")
        
        # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if backup:
            backup_file = directory_path / "train.parquet.backup"
            print(f"åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
            shutil.copy2(parquet_file, backup_file)
        
        # æ‰©å±•æ•°æ®
        print(f"æ­£åœ¨æ‰©å±•æ•°æ® {factor} å€...")
        expanded_df_list = [df] * factor
        expanded_df = pd.concat(expanded_df_list, ignore_index=True)
        
        new_size = len(expanded_df)
        print(f"æ‰©å±•åæ•°æ®è¡Œæ•°: {new_size}")
        
        # ä¿å­˜æ‰©å±•åçš„æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_file = directory_path / "train.parquet.tmp"
        print(f"æ­£åœ¨ä¿å­˜æ‰©å±•åçš„æ•°æ®...")
        expanded_df.to_parquet(temp_file, index=False)
        
        # æ›¿æ¢åŸæ–‡ä»¶
        print(f"æ­£åœ¨æ›¿æ¢åŸæ–‡ä»¶...")
        shutil.move(temp_file, parquet_file)
        
        print(f"âœ… æˆåŠŸå®Œæˆï¼æ•°æ®å·²ä» {original_size} è¡Œæ‰©å±•åˆ° {new_size} è¡Œ")
        
        if backup:
            print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¿å­˜åœ¨: {backup_file}")
            
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        temp_file = directory_path / "train.parquet.tmp"
        if temp_file.exists():
            temp_file.unlink()
        raise e


def main():
    parser = argparse.ArgumentParser(
        description="æ‰©å±•parquetæ–‡ä»¶æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python expand_parquet_data.py --directory ./data/robovqa --factor 4
  python expand_parquet_data.py -d /home/user/data -f 5 --no-backup
        """
    )
    
    parser.add_argument(
        "--directory", "-d",
        type=str,
        required=True,
        help="åŒ…å«train.parquetæ–‡ä»¶çš„ç›®å½•è·¯å¾„"
    )
    
    parser.add_argument(
        "--factor", "-f",
        type=int,
        required=True,
        help="æ•°æ®æ‰©å±•å€æ•°ï¼ˆå¿…é¡»å¤§äº0ï¼‰"
    )
    
    parser.add_argument(
        "--no-backup",
        action="store_true",
        help="ä¸åˆ›å»ºå¤‡ä»½æ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    try:
        expand_parquet_data(
            directory=args.directory,
            factor=args.factor,
            backup=not args.no_backup
        )
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main() 